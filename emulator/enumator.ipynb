{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit7b1f69f4b8694c11a491566f0cc14780",
   "display_name": "Python 3.7.7 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '../benchmark/metrics'\n",
    "percentile = '90th'\n",
    "\n",
    "schedule = pd.read_csv('%s/schedule.csv' % BASE_PATH, index_col=0)\n",
    "params = schedule.columns\n",
    "indexes = schedule.index\n",
    "# scaling scheule\n",
    "scaler = MinMaxScaler()\n",
    "schedule = pd.DataFrame(scaler.fit_transform(schedule), columns=params, index=indexes)\n",
    "\n",
    "latency = pd.read_csv('%s/processed/latency.csv' % BASE_PATH, index_col=0)\n",
    "states = pd.read_csv('%s/processed/states_%s.csv' % (BASE_PATH, percentile), index_col=0)\n",
    "states_cols = pd.read_csv('../benchmark/meta/state_meta.csv')['name']\n",
    "states = states[states_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Couldn't find program: 'falses'\n"
     ]
    }
   ],
   "source": [
    "%%script falses\n",
    "df = pd.concat([latency, states], axis=1)\n",
    "fig, ax = plt.subplots(figsize=(15, 10))  \n",
    "ans = sns.heatmap(df.corr(), linewidths=.5, xticklabels=df.columns, yticklabels=df.columns, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# spliting training and testing sets\n",
    "X = schedule\n",
    "y = pd.concat([states, latency], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "states_y_train = y_train[states.columns]\n",
    "states_y_test = y_test[states.columns]\n",
    "latency_y_train = y_train[latency.columns]\n",
    "latency_y_test = y_test[latency.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct env prediction model using RF or GB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, mean_squared_log_error, mean_absolute_error, explained_variance_score, r2_score\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# build regression model for every column\n",
    "def train(my_X, my_y, cols):\n",
    "    for i, col in enumerate(cols):\n",
    "        y = my_y[col].tolist()\n",
    "\n",
    "        # evaluate the model and collect the scores\n",
    "        best_model = None\n",
    "        best_score = -1e6\n",
    "\n",
    "        # choose the best model from RF and GB\n",
    "        rf = RandomForestRegressor(random_state=1000)\n",
    "        # gb = GradientBoostingRegressor(random_state=1000)\n",
    "        models = [rf]\n",
    "        for model in models:\n",
    "            # define the evaluation procedure\n",
    "            cv = RepeatedKFold(n_splits=10, n_repeats=10, random_state=43)\n",
    "            n_scores = cross_val_score(model, my_X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "            if np.mean(n_scores) > best_score:\n",
    "                best_model = model\n",
    "                best_score = np.mean(n_scores)\n",
    "                model.fit(X=my_X, y=y)\n",
    "                joblib.dump(best_model, './models/%s.joblib' % col)\n",
    "            print('%s: %.3f (%.3f)' % (col, np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accurancy of testing set\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import ceil\n",
    "\n",
    "def test(my_X, my_y, cols):\n",
    "    for col in cols:\n",
    "        model = joblib.load('./models/%s.joblib' % col)\n",
    "        score = model.score(my_X, my_y[col])\n",
    "        print('Test %s: %.3f' % (col, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "network_request_FetchConsumer_TotalTimeMs: 0.705 (0.033)\n",
      "network_request_Fetch_MessageConversionsTimeMs: 0.704 (0.033)\n",
      "network_request_Produce_TotalTimeMs: 0.713 (0.063)\n",
      "network_socket_FetchConsumer_NetworkProcessorAvgIdlePercent: 0.981 (0.008)\n",
      "network_socket_FetchConsumer_RequestHandlerAvgIdlePercent: 0.953 (0.032)\n",
      "os_open_fd_count: 0.999 (0.000)\n",
      "os_process_cpu_time: 0.848 (0.014)\n",
      "server_broker_topics_TotalProduceRequestsPerSec: 0.853 (0.035)\n",
      "server_broker_topics_AllTopicsBytesIn: 0.853 (0.014)\n",
      "server_broker_topics_AllTopicsBytesOut: 0.712 (0.035)\n",
      "threading_thread_count: 0.996 (0.001)\n"
     ]
    }
   ],
   "source": [
    "train(X_train, states_y_train, states.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test network_request_FetchConsumer_TotalTimeMs: 0.717\n",
      "Test network_request_Fetch_MessageConversionsTimeMs: 0.717\n",
      "Test network_request_Produce_TotalTimeMs: 0.700\n",
      "Test network_socket_FetchConsumer_NetworkProcessorAvgIdlePercent: 0.982\n",
      "Test network_socket_FetchConsumer_RequestHandlerAvgIdlePercent: 0.974\n",
      "Test os_open_fd_count: 0.999\n",
      "Test os_process_cpu_time: 0.851\n",
      "Test server_broker_topics_TotalProduceRequestsPerSec: 0.848\n",
      "Test server_broker_topics_AllTopicsBytesIn: 0.846\n",
      "Test server_broker_topics_AllTopicsBytesOut: 0.724\n",
      "Test threading_thread_count: 0.996\n"
     ]
    }
   ],
   "source": [
    "test(X_test, states_y_test, states.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "min: 0.914 (0.011)\n",
      "max: 0.945 (0.006)\n",
      "median: 0.996 (0.000)\n",
      "mean: 0.996 (0.000)\n",
      "std: 0.992 (0.001)\n",
      "25th: 0.986 (0.002)\n",
      "50th: 0.996 (0.000)\n",
      "75th: 0.998 (0.000)\n",
      "90th: 0.998 (0.000)\n",
      "95th: 0.998 (0.000)\n",
      "99th: 0.984 (0.002)\n"
     ]
    }
   ],
   "source": [
    "train(X_train, latency_y_train, latency.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test min: 0.907\n",
      "Test max: 0.946\n",
      "Test median: 0.996\n",
      "Test mean: 0.996\n",
      "Test std: 0.993\n",
      "Test 25th: 0.986\n",
      "Test 50th: 0.996\n",
      "Test 75th: 0.998\n",
      "Test 90th: 0.999\n",
      "Test 95th: 0.998\n",
      "Test 99th: 0.984\n"
     ]
    }
   ],
   "source": [
    "test(X_test, latency_y_test, latency.columns)"
   ]
  }
 ]
}